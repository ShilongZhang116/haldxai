# build_clean_parquet.py
# --------------------------------------------------------
"""
æ¸…æ´— collected_ext_* / all_annotated_* å­—ç¬¦ä¸²åˆ—
å¹¶å†™æˆ parquet ä¾›ä¸‹æ¸¸æ£€ç´¢ / ç‰¹å¾å·¥ç¨‹ä½¿ç”¨
"""

from __future__ import annotations
import pandas as pd, logging
from pathlib import Path
import typer, rich, sys

log = logging.getLogger(__name__)
logging.basicConfig(
    level=logging.INFO,
    stream=sys.stdout,           # æ˜ç¡®æŒ‡å®šåˆ° stdout
    format="%(message)s"         # åªæ‰“å°æ¶ˆæ¯æœ¬èº«
)

# ---------- åŸºç¡€æ¸…æ´— ----------
def _clean(s):
    if pd.isna(s):
        return s
    return (str(s)
            .replace(",", ";")
            .replace('"', "")
            .replace("'", "")
            .replace("\n", " ")
            .strip())

def _clean_df(df: pd.DataFrame, cols: list[str]):
    for c in cols:
        if c in df.columns:
            df[c] = df[c].apply(_clean)
    return df

# ---------- ä¸»å‡½æ•° ----------
def build_clean(project_root: Path, *, force: bool = False):
    root   = Path(project_root)
    finals = root / "data" / "finals"
    cache  = root / "cache"
    cache.mkdir(exist_ok=True)

    # â‘  è¯»å–
    f_nodes = finals / "collected_ext_nodes.csv"
    f_rels  = finals / "collected_ext_relations.csv"
    f_ents  = finals / "all_annotated_entities.csv"
    f_rls   = finals / "all_annotated_relationships.csv"

    df_nodes = pd.read_csv(f_nodes, low_memory=False)
    df_rels  = pd.read_csv(f_rels,  low_memory=False)
    df_ents  = pd.read_csv(f_ents,  low_memory=False)
    df_rls   = pd.read_csv(f_rls,   low_memory=False)

    log.info("âœ” åŸå§‹è¯»å–å®Œæˆ")
    log.info(f"â€¢ collected_ext_nodes.csv  ({len(df_nodes):,} è¡Œ)")
    log.info(f"â€¢ collected_ext_relations.csv  ({len(df_rels):,} è¡Œ)")
    log.info(f"â€¢ all_annotated_entities.csv  ({len(df_ents):,} è¡Œ)")
    log.info(f"â€¢ all_annotated_relationships.csv  ({len(df_rls):,} è¡Œ)")

    # â‘¡ æ¸…æ´—
    _clean_df(df_nodes, ["entity_name"])
    _clean_df(df_rels,  ["source_name", "target_name"])
    _clean_df(df_ents,  ["main_text"])
    _clean_df(df_rls,   ["source_main_text", "target_main_text"])

    # â‘¢ å†™ parquetï¼ˆè‹¥å·²å­˜åœ¨ä¸”é force â†’ è·³è¿‡ï¼‰
    def _dump(df, out_name):
        out_path = cache / out_name
        if out_path.exists() and not force:
            log.warning(f"è·³è¿‡ {out_name}ï¼ˆå·²å­˜åœ¨ï¼Œ--force å¯è¦†ç›–ï¼‰")
            return
        df.to_parquet(out_path, index=False)
        log.info(f"ğŸ“¦ å†™å‡º {out_name}  ({len(df):,} rows)")

    _dump(df_nodes, "collected_ext_nodes_clean.parquet")
    _dump(df_rels,  "collected_ext_rels_clean.parquet")
    _dump(df_ents,  "annotated_entities_clean.parquet")
    _dump(df_rls,   "annotated_relationships_clean.parquet")

    rich.print("[bold green]ğŸ‰ æ¸…æ´—å®Œæ¯•[/]")

# ---------- Typer CLI ----------
app = typer.Typer()

@app.command()
def run(root: str = typer.Option(..., help="é¡¹ç›®æ ¹ç›®å½•"),
        force: bool = typer.Option(False, "--force/-f", help="å·²å­˜åœ¨æ—¶è¦†ç›–")):
    """æ¸…æ´—å¹¶å¯¼å‡º Parquet"""
    build_clean(Path(root), force=force)

if __name__ == "__main__":
    app()
