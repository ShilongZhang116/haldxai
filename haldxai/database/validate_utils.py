#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""validate_utils.py
~~~~~~~~~~~~~~~~~~~~
ä¸€ä¸ªæ—¢å¯ **import**ï¼Œä¹Ÿå¯ **CLI** è¿è¡Œçš„å·¥å…·æ¨¡å—ï¼Œå¸®åŠ©ä½ ï¼š

1. **validate_graph** â€” æ ¡éªŒ *nodes.csv* / *relationships.csv* æ˜¯å¦é…å¥—ï¼›
2. **clean_relationships** â€” æ‰¾åˆ°æ‚¬ç©ºå…³ç³»åï¼Œå†™å‡ºä¸€ä¸ªâ€œå·²æ¸…ç†â€çš„å…³ç³» CSVï¼›

ç”¨æ³•ç¤ºä¾‹
---------
âŠ äº¤äº’å¼æ£€æŸ¥
```
from validate_utils import validate_graph, clean_relationships
ok, miss_df = validate_graph("nodes.csv", "rels.csv")
if not ok:
    clean_relationships("nodes.csv", "rels.csv", "rels_clean.csv")
```

â‹ CLI ä¸€é”®ä¿®å¤
```
python -m validate_utils \
   --nodes data/database/nodes.csv \
   --rels  data/database/relationships.csv \
   --fix   data/database/relationships_clean.csv
```
"""
from __future__ import annotations

import argparse
import sys
from pathlib import Path
from typing import Tuple

import pandas as pd

__all__ = [
    "validate_graph",
    "clean_relationships",
]

# ---------------------------------------------------------------------------
# æ ¸å¿ƒæ ¡éªŒå‡½æ•°
# ---------------------------------------------------------------------------

def _load_node_set(nodes_path: Path, id_col: str) -> set[str]:
    """è¯»å– nodes.csv ä¸­çš„ ID é›†åˆ (str)ã€‚"""
    return set(
        pd.read_csv(nodes_path, usecols=[id_col], dtype=str)[id_col].astype(str)
    )


def _load_rels(rels_path: Path, start_col: str, end_col: str) -> pd.DataFrame:
    """è¯»å– relationships.csv æŒ‡å®šä¸¤åˆ—å¹¶è½¬ strã€‚"""
    return pd.read_csv(rels_path, usecols=[start_col, end_col], dtype=str)


def validate_graph(
    project_root: str | Path,
    nodes_path: str | Path,
    rels_path: str | Path,
    id_col: str = "node_id:ID",
    start_col: str = ":START_ID",
    end_col: str = ":END_ID",
    sample: int = 5,
) -> Tuple[bool, pd.DataFrame]:
    """æ£€æŸ¥å…³ç³»æ–‡ä»¶æ˜¯å¦å¼•ç”¨äº†ç¼ºå¤±èŠ‚ç‚¹ã€‚

    è¿”å› *(is_ok, missing_df)*ï¼Œå…¶ä¸­ `missing_df` åˆ—ä¸º [`role`, `missing_id`].
    """
    nodes_path, rels_path = Path(project_root / nodes_path), Path(project_root / rels_path)

    node_set = _load_node_set(nodes_path, id_col)
    rels_df  = _load_rels(rels_path, start_col, end_col)

    missing_start = rels_df.loc[~rels_df[start_col].isin(node_set), start_col]
    missing_end   = rels_df.loc[~rels_df[end_col].isin(node_set), end_col]

    missing_df = pd.concat([
        pd.DataFrame({"role": "start", "missing_id": missing_start}),
        pd.DataFrame({"role": "end",   "missing_id": missing_end}),
    ]).drop_duplicates()

    is_ok = missing_df.empty

    if is_ok:
        print("âœ… æ ¡éªŒé€šè¿‡ï¼šrelationships.csv çš„æ‰€æœ‰èŠ‚ç‚¹å‡å­˜åœ¨äº nodes.csvã€‚")
    else:
        print(f"âŒ æ£€æµ‹åˆ°ç¼ºå¤±èŠ‚ç‚¹ï¼š{len(missing_df)} æ¡")
        if sample > 0:
            print(missing_df.head(sample))

    return is_ok, missing_df


# ---------------------------------------------------------------------------
# æ¸…ç†å‡½æ•°
# ---------------------------------------------------------------------------

def clean_relationships(
    project_root: str | Path,
    nodes_path: str | Path,
    rels_path: str | Path,
    output_path: str | Path,
    id_col: str = "node_id:ID",
    start_col: str = ":START_ID",
    end_col: str = ":END_ID",
) -> None:
    """ç”Ÿæˆä¸€ä¸ªå·²ç§»é™¤æ‚¬ç©ºå…³ç³»çš„æ–° CSVã€‚

    - ä»…å½“å…³ç³»ä¸¤ç«¯èŠ‚ç‚¹ *éƒ½* åœ¨èŠ‚ç‚¹æ–‡ä»¶ä¸­å‡ºç°æ—¶ä¿ç•™ã€‚
    - å…¶ä½™åˆ—åŸæ ·ä¿ç•™ã€‚
    """
    nodes_path, rels_path, output_path = map(Path, (project_root / nodes_path, project_root / rels_path, project_root / output_path))

    node_set = _load_node_set(nodes_path, id_col)
    rels_df  = pd.read_csv(rels_path, dtype=str)

    mask_start = rels_df[start_col].isin(node_set)
    mask_end   = rels_df[end_col].isin(node_set)
    cleaned_df = rels_df[mask_start & mask_end]

    output_path.parent.mkdir(parents=True, exist_ok=True)
    cleaned_df.to_csv(output_path, index=False, encoding="utf-8")

    removed = len(rels_df) - len(cleaned_df)
    print(f"ğŸ§¹ å·²å†™å‡º cleaned CSV â†’ {output_path} (ç§»é™¤ {removed} æ¡æ‚¬ç©ºå…³ç³»)")


# ---------------------------------------------------------------------------
# CLI å…¥å£
# ---------------------------------------------------------------------------


def _parse_args(argv: list[str] | None = None) -> argparse.Namespace:
    p = argparse.ArgumentParser(description="æ ¡éªŒå¹¶å¯æ¸…ç† relationships.csv ä¸­çš„æ‚¬ç©ºèŠ‚ç‚¹")
    p.add_argument("--nodes", required=True, type=Path, help="nodes.csv è·¯å¾„")
    p.add_argument("--rels",  required=True, type=Path, help="relationships.csv è·¯å¾„")
    p.add_argument("--sample", type=int, default=5, help="ç¼ºå¤±æ ·ä¾‹æ‰“å°æ•°é‡ (<=0 ä¸æ‰“å°)")
    p.add_argument("--fix",    type=Path, help="è¾“å‡ºå·²æ¸…ç† CSV çš„ä¿å­˜è·¯å¾„ (å¯è¦†ç›–åŸæ–‡ä»¶)")
    return p.parse_args(argv)


def main(argv: list[str] | None = None) -> None:  # noqa: D401
    args = _parse_args(argv)

    ok, missing = validate_graph(args.nodes, args.rels, sample=args.sample)

    if (not ok) and args.fix:
        clean_relationships(args.nodes, args.rels, args.fix)
        ok = True  # è®¤ä¸ºå·²ä¿®å¤

    sys.exit(0 if ok else 1)


if __name__ == "__main__":  # pragma: no cover
    main()
