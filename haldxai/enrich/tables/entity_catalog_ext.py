#!/usr/bin/env python3
# -*- coding: utf-8 -*-
from __future__ import annotations

import hashlib
import re
from pathlib import Path

import pandas as pd

from haldxai.enrich.tables.loader import load_name2id, save_name2id
from haldxai.enrich.tables.utils import alloc_id

def _clean_source(src: str) -> str:
    """
    ç»Ÿä¸€å‹ç¼© source_file:
    â–¸ hald_ageanno__pathways__std.csv  â†’  ageanno__pathways
    """
    src = Path(src).name                       # åªä¿ç•™æ–‡ä»¶å
    src = re.sub(r"^hald_", "", src)
    src = re.sub(r"__std\.csv$", "", src)
    return src

def build_entity_catalog_ext(
        project_root: Path,
        df_ext_nodes: pd.DataFrame,
        *,
        force: bool = False,
) -> pd.DataFrame:
    """
    Parameters
    ----------
    df_ext_nodes : DataFrame
        å¿…é¡»åŒ…å«åˆ— `entity_name, entity_type, primary_info, extra_json, source_file`
        ï¼ˆç”± ext_collect.py è¾“å‡ºï¼‰
    name2id : dict | Path
        åç§° â†’ HALD å®ä½“ ID çš„æ˜ å°„ï¼Œæˆ–æ˜ å°„ JSON è·¯å¾„
    lowercase_key : bool , default=True
        æ˜¯å¦å¯¹æ¯”æ—¶ç»Ÿä¸€è½¬å°å†™ï¼ˆæ¨èï¼‰

    Returns
    -------
    DataFrame
        æ‰©å±•ç›®å½•ï¼Œå­—æ®µè§æ¨¡å—é¡¶éƒ¨è¯´æ˜
    """
    db_dir      = project_root / "data/database"
    db_dir.mkdir(parents=True, exist_ok=True)

    output_csv = db_dir / "entity_catalog_ext.csv"

    if output_csv.exists() and not force:
        print(f"ğŸŸ¡ entity_catalog_ext.csv å·²å­˜åœ¨ï¼ˆè·³è¿‡ï¼‰ã€‚pass `force=True` ä»¥é‡æ–°ç”Ÿæˆã€‚")
        return pd.read_csv(output_csv)

    print("â–¶ æ„å»º entity_catalog_ext.csv â€¦")

    # â”€â”€ 0) æ˜ å°„åŠ è½½ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    name2id = load_name2id(project_root)

    # â”€â”€ 1) å­—æ®µè§„èŒƒ & è½»åº¦æ¸…æ´— â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    need_cols = ["entity_name", "entity_type", "primary_info", "extra_json", "source_file"]
    miss = [c for c in need_cols if c not in df_ext_nodes.columns]
    if miss:
        raise ValueError(f"df_ext_nodes ç¼ºå°‘åˆ—: {miss}")

    df = (
        df_ext_nodes[need_cols]
        .rename(columns={"source_file": "source"})
        .copy()
    )
    df["source"] = df["source"].map(_clean_source)

    # â”€â”€ 2) ç”Ÿæˆ entity_id â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    df["entity_id"] = df["entity_name"].apply(lambda n: alloc_id(name2id, n))

    # â”€â”€ 3) è‡ªå¢ä¸»é”® â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    df.insert(0, "ext_pk", range(1, len(df) + 1))

    df.to_csv(output_csv, index=False, encoding="utf-8-sig")
    print(f"âœ“ entity_catalog_ext å†™å‡º {len(df):,} è¡Œ â†’ {output_csv}")

    save_name2id(project_root, name2id)  # â‘¡ æŠŠå¯èƒ½æ–°å¢çš„æ˜ å°„è½ç›˜
    print("âœ“ name2id.json å·²æ›´æ–°ï¼Œå½“å‰æ¡æ•° =", len(name2id))

    return df