# haldxai/enrich/tables/relation_types.py
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from __future__ import annotations

import json
import re
from pathlib import Path
from typing import Dict, Any

import pandas as pd

from haldxai.enrich.tables.loader import load_name2id, save_name2id
from haldxai.enrich.tables.utils import alloc_id

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å†…éƒ¨å·¥å…·
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _clean_source(src: str) -> str:
    """
    æŠŠ `hald_xxx__yyy__std.csv` â†’ `xxx__yyy`
    """
    src = re.sub(r"^hald_", "", src)
    src = re.sub(r"__std\.csv$", "", src)
    return src

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# æ ¸å¿ƒæ„å»ºå‡½æ•°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_relation_types(
        project_root: Path,
        df_ext_rels: pd.DataFrame,
        df_llm_relationships: pd.DataFrame,
        df_pred_relations_llm: pd.DataFrame,
        df_pred_relations_articles: pd.DataFrame,
        *,
        force: bool = False
) -> pd.DataFrame:
    """
    Parameters
    ----------
    project_root : Path
        é¡¹ç›®æ ¹ç›®å½•
    src : dict
        `load_sources()` è¿”å›çš„ç¼“å­˜å¯¹è±¡
    out_dir : Path | None
        æœ€ç»ˆ CSV è¾“å‡ºç›®å½•ï¼›é»˜è®¤å†™å…¥ `<project_root>/data/database`
    force : bool
        True åˆ™è¦†ç›–å·²å­˜åœ¨æ–‡ä»¶
    """
    db_dir = project_root / "data/database"
    db_dir.mkdir(parents=True, exist_ok=True)

    output_csv = db_dir / "relation_types.csv"

    if output_csv.exists() and not force:
        print(f"ğŸŸ¡ relation_types.csv å·²å­˜åœ¨ï¼ˆè·³è¿‡ï¼‰ã€‚pass `force=True` ä»¥é‡æ–°ç”Ÿæˆã€‚")
        return pd.read_csv(output_csv)

    print("â–¶ æ„å»º relation_types.csv â€¦")

    # â”€â”€ 0) æ˜ å°„åŠ è½½ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    name2id = load_name2id(project_root)

    # -------- 1. å¤–éƒ¨æ ‡å‡†åº“å…³ç³» --------
    ext = df_ext_rels[["source_name", "target_name",
                          "relation_type", "source_file"]].rename(
        columns={
            "source_name": "source_entity_name",
            "target_name": "target_entity_name",
            "source_file": "source"
        }
    )
    mask = ext["source"].str.startswith("hald_")
    ext.loc[mask, "source"] = ext.loc[mask, "source"].map(_clean_source)

    # -------- 2. äººå·¥æ ‡æ³¨ LLM å…³ç³» --------
    ann = df_llm_relationships[["source_main_text", "target_main_text",
                          "relation_type", "model_name"]].rename(
        columns={
            "source_main_text": "source_entity_name",
            "target_main_text": "target_entity_name",
            "model_name": "source"
        }
    )

    # -------- 3. BERT é¢„æµ‹å…³ç³»ï¼ˆLLM promptsï¼‰ --------
    bert_llm = df_pred_relations_llm[["input", "predicted_relation_type"]].copy()
    bert_llm["source"] = "bert_model_prediction"
    bert_llm[["source_entity_name", "target_entity_name"]] = bert_llm["input"].str.extract(
        r"<e1>(.*?)</e1>.*?<e2>(.*?)</e2>", expand=True
    )
    bert_llm = bert_llm.rename(columns={"predicted_relation_type": "relation_type"})[
        ["source_entity_name", "target_entity_name", "relation_type", "source"]
    ]

    # -------- 4. BERT é¢„æµ‹å…³ç³»ï¼ˆå…¨æ–‡ï¼‰ --------
    bert_art = df_pred_relations_articles[["e1", "e2", "predicted_relation_type"]].rename(
        columns={
            "e1": "source_entity_name",
            "e2": "target_entity_name",
            "predicted_relation_type": "relation_type"
        }
    )
    bert_art["source"] = "bert_model_prediction"

    # -------- 5. åˆå¹¶å»é‡ --------
    all_rels = pd.concat([ext, ann, bert_llm, bert_art], ignore_index=True)
    all_rels = all_rels.dropna(subset=["source_entity_name", "target_entity_name"])
    all_rels["source_entity_name"] = all_rels["source_entity_name"].str.strip()
    all_rels["target_entity_name"] = all_rels["target_entity_name"].str.strip()

    # -------- 6. æ˜ å°„ entity_id --------
    all_rels["source_entity_id"] = all_rels["source_entity_name"].apply(lambda n: alloc_id(name2id, n))
    all_rels["target_entity_id"] = all_rels["target_entity_name"].apply(lambda n: alloc_id(name2id, n))

    all_rels = all_rels.dropna(subset=["source_entity_id", "target_entity_id"])

    # -------- 7. ç”Ÿæˆ relation_id / PK --------
    all_rels["relation_id"] = (
        "Relation-" +
        all_rels["source_entity_id"].str.removeprefix("Entity-") +
        "-" +
        all_rels["target_entity_id"].str.removeprefix("Entity-")
    )

    all_rels.insert(0, "rel_pk", range(1, len(all_rels) + 1))

    cols = ["rel_pk", "relation_id",
            "source_entity_id", "target_entity_id",
            "source_entity_name", "target_entity_name",
            "relation_type", "source"]
    final_df = all_rels[cols]

    # ---- â‘¥ ä¿å­˜ --------------------------------------------------------------
    final_df.to_csv(output_csv, index=False, encoding="utf-8-sig")
    print(f"âœ“ entity_types_pred å†™å‡º {len(final_df):,} è¡Œ â†’ {output_csv}")

    save_name2id(project_root, name2id)  # â‘¡ æŠŠå¯èƒ½æ–°å¢çš„æ˜ å°„è½ç›˜
    print("âœ“ name2id.json å·²æ›´æ–°ï¼Œå½“å‰æ¡æ•° =", len(name2id))

    return final_df

