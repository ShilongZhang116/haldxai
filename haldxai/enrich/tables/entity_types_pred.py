# haldxai/enrich/tables/entity_types_pred.py
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""build_entity_types_pred

æŠŠ `src["PredEnts"]` ä¸­çš„å®ä½“ç±»å‹é¢„æµ‹ç»“æœæ•´ç†ä¸ºå¯å…¥åº“ CSVã€‚

è¾“å‡ºå­—æ®µ
--------
pred_pk | pmid | entity_id | entity_name
| predicted_type | similarity
"""

from __future__ import annotations

import json
from pathlib import Path
from typing import Any

import pandas as pd

from haldxai.enrich.tables.loader import load_name2id, save_name2id
from haldxai.enrich.tables.utils import alloc_id


def build_entity_types_pred(
    project_root: Path,
    df_pred_entities: pd.DataFrame,
    *,
    force: bool = False
) -> pd.DataFrame:
    """
    Parameters
    ----------
    project_root : Path
        é¡¹ç›®æ ¹ç›®å½•ï¼Œç”¨äºå®šä½ cache/mappingã€è¾“å‡ºç›®å½•ç­‰ã€‚
    df_pred_ents : pd.DataFrame
        loader è¿”å›çš„ `src["PredEnts"]`ï¼Œè‡³å°‘è¦æœ‰ï¼š
        pmid | main_text | predicted_type | similarity
    name2id : dict[str,str] | None
        å·²ç»åŠ è½½å¥½çš„æ˜ å°„è¡¨ï¼ˆå¯é€‰ï¼›ä¸ä¼ åˆ™è‡ªåŠ¨ä» cache è¯»å–ï¼‰
    """

    db_dir = project_root / "data/database"
    db_dir.mkdir(parents=True, exist_ok=True)

    output_csv = db_dir / "entity_types_pred.csv"

    if output_csv.exists() and not force:
        print(f"ğŸŸ¡ entity_types_pred.csv å·²å­˜åœ¨ï¼ˆè·³è¿‡ï¼‰ã€‚pass `force=True` ä»¥é‡æ–°ç”Ÿæˆã€‚")
        return pd.read_csv(output_csv)

    print("â–¶ æ„å»º entity_types_pred.csv â€¦")

    # â”€â”€ 0) æ˜ å°„åŠ è½½ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    name2id = load_name2id(project_root)

    # ---- â‘  é€‰åˆ—å¹¶é‡å‘½å ----------------------------------------------------
    cols_needed = ["pmid", "main_text", "predicted_type", "similarity"]
    df = df_pred_entities.loc[:, cols_needed].rename(
        columns={"main_text": "entity_name"}
    ).copy()

    # ---- â‘¡ PMID è§„èŒƒåŒ– ------------------------------------------------------
    df["pmid"] = (
        pd.to_numeric(df["pmid"], errors="coerce")
        .fillna(0).astype(int).astype(str).replace("0", "")
    )

    # ---- â‘¢ entity_id æ˜ å°„ ---------------------------------------------------
    df["entity_id"] = df["entity_name"].apply(lambda n: alloc_id(name2id, n))

    # ---- â‘£ æ·»åŠ è‡ªå¢ä¸»é”® ------------------------------------------------------
    df.insert(0, "pred_pk", range(1, len(df) + 1))

    # ---- â‘¤ å­—æ®µé¡ºåºå›ºå®š ------------------------------------------------------
    df = df[
        [
            "pred_pk",
            "pmid",
            "entity_id",
            "entity_name",
            "predicted_type",
            "similarity",
        ]
    ]

    # ---- â‘¥ ä¿å­˜ --------------------------------------------------------------
    df.to_csv(output_csv, index=False, encoding="utf-8-sig")
    print(f"âœ“ entity_types_pred å†™å‡º {len(df):,} è¡Œ â†’ {output_csv}")

    save_name2id(project_root, name2id)  # â‘¡ æŠŠå¯èƒ½æ–°å¢çš„æ˜ å°„è½ç›˜
    print("âœ“ name2id.json å·²æ›´æ–°ï¼Œå½“å‰æ¡æ•° =", len(name2id))

    return df

